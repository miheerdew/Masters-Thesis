\chapter{Graph games}
We will look at a class of two player games on graphs. The two players will be called Player 0 and Player 1 (abbreviated as \Player{0}, \Player{1}). Although we will only look at specific games later, all of them fit into a general framework which will be discussed now.
\section{Formalism}
\label{sec:formalism}
The game is played on a directed graph $G=(V_0,V_1,E)$ whose vertices are $V=V_0 \sqcup V_1$ and edges are $E \subseteq V\times V$. The vertices $V$ are partitioned as $(V_0,V_1)$ -- those belonging to P0 and P1 respectively. We will always assume that $G$ has no dead ends ($\forall v \in V \; \exists w \, (v,w) \in E$). For $n \geq 0$, let $\PF[n]$ denote the set of paths in $G$ of length $n$ (in paritcular $\PF[0]=V$, $\PF[1]=E$). $\PF$ will denote the set of all finite paths in $G$, and by $\PI$ the set of all infinite paths. $N(u)=\set{v \mid (u,v) \in E}$ is the set of outgoing neighbours of $u$.

The game starting from $v_0 \in V$ is played as follows
\begin{itemize}
  \item A token is initially placed in $v_0$
  \item At any stage if the token is in a vertex $v \in V_i$, then \Player{i} has to move the token to a vertex $w \in N(v)$
\end{itemize}
A concrete realization of this play will be an infinite path $\pi \in \PI$
\[
  \pi = v_0 v_1 v_2 \ldots
\]
Where
\begin{itemize}
  \item $v_0$ was the vertex where the play started
  \item If $v_i \in V_j$, then at ${i+1}^\text{th}$ stage \Player{j} decided to move the token to $v_{i+1} \in N(v_i)$
\end{itemize}
After this infinite path $\pi$ is played, \Player{0} pays $f(\pi)$ units of money to \Player{1}. Where $f : \PI \to \Reals
$ is the payoff function. When $f(\pi) < 0$ this is interpreted as \Player{1} paying $|f(\pi)|$ units to \Player{0}. \Player{0}'s objective is to minimize $f(\pi)$ while \Player{1}'s objective is to maximize it.

This game will be denoted by $\G=(G,f)$. And in particular, the game  starting at $v_0$ by $(\G,v_0)$.

\subsection{Strategy}
A strategy for \Player{i} is a function $\sigma : \PF \cap V^*V_{i} \mapsto V$, which assigns to each possible finite path $\alpha u$ ending in $ u \in V_i$ a neighbor $\sigma(\alpha u) \in N(u)$.

Intuitively this is a recipe for \Player{i} to make his moves in the game. If at the \nth\ stage it is \Player{i}'s turn, and the token has been moved to $v_0v_1 \ldots v_{n-1}$ so far (with $v_{n-1} \in V_i$), the strategy recommends playing $v_n=\sigma(v_0v_1 \ldots v_{n-1})$

An infinite path $\pi= v_0 v_1 \ldots$ is said to conform with a strategy $\sigma$ of \Player{i} if whenever $v_j \in V_i$, $v_{j+1}=\sigma(v_0 v_1 \ldots v_j)$.

Consider strategies $(\sigma,\tau)$ for \Player{0} and \Player{1} respectively. Starting at $v_0$ there is a unique path $\pi^{v_0}_{\sigma\tau}= v_0 v_1 \ldots $ which conforms with both $\sigma$ and $\tau$, given by
\begin{equation*}
v_{i+1} = \begin{cases}
\sigma(v_0v_1\ldots v_i) & \text{if}\  v_i \in V_0\\
\tau(v_0v_1\ldots v_i) & \text{if}\  v_i \in V_1
\end{cases}
\end{equation*}
Let $f^{v}(\sigma,\tau)$ denote $f(\pi^v_{\sigma\tau})$.

\subsubsection{Finite memory strategies}
From a computational perspective it is important to have a finite implementation of a strategy (which is generally an infinite object). Finite memory strategies are a subclass for which this is possible. A finite memory strategy for \Player{i} is a tuple $(M,\delta,g,m_0)$, where $M$ is a finite set (also called as ``the memory"), and $m_0 \in M$.
\[
    \delta : M \times V \to M
\]
is the update function for the memory and
\[
    g : M \times V_i \to V
\]
is the action function (with $\forall u \; g(.,u) \in N(u)$).

To implement this strategy start with $m_0$. At the \nth\ move if $v_{n-1} \in V_i$ then play $v_n=g(m_{n-1},v_{n-1})$ (otherwise the opponent decides $v_n$) and set $m_n = \delta(m_{n-1},v_n)$.

\subsubsection{Positional strategy}
An important special case of finite memory strategies is when $M$ is singleton. These are called positional or memoryless strategies. In this case
\[
    g : V_i \to V
\]
and the resulting strategy $\sigma$ is just
\[
    \sigma( v_0 v_1 \ldots v_n ) = g(v_n)
\]
which only depends on the current state the token is in.

Let $\rho$ be a positional strategy for \Player{i} in $G$, then $G_{\rho}$ will denote the graph obtained from $G$ by restricting the outgoing edges of every $u\in V_i$ to the unique edge given by $\rho$. Moreover if $\bar{\rho}$ is a strategy for \Player{1-i} then $G_{\rho\bar{\rho}}$ is defined as $(G_\rho)_{\bar{\rho}}$.

An infinite path $\pi$ is called ultimately periodic if for some $k \geq 0$
\begin{equation}
    \pi = v_0 v_1 \ldots v_{k-1} (v_k v_{k+1} \ldots v_r)^\omega \label{eqn:periodic}
\end{equation}
Denote $\prefix(\pi)=v_0 v_1 \ldots v_{k-1}$ and $\cycle(\pi)=v_k v_{k+1} \ldots v_r$.

\label{par:ultperiodic} Let $(\sigma,\tau)$ be positional strategies for \Player{0} and \Player{1}. Starting any $v_0 \in V$, the path $\pi^{v_0}_{\sigma\tau}$ is ultimately periodic with all $v_i$'s distinct in \eqref{eqn:periodic}.  $\cycle(\pi^{v_0}_{\sigma\tau})$ is the unique cycle reachable from $v_0$ in $G_{\sigma\tau}$, and $\prefix(\pi^{v_0}_{\sigma\tau})$ is the path leading to that cycle.

Denote by \ST{i} the set of all strategies of \Player{i}. Often $\sigma,\tau$ (and their variants) will be used to denote the strategies for \Player{0} and \Player{1} respectively.


\section{Optimal play}
%TODO: Should I just say that one cannot unilaterally deviate from the optimal.
How should \Player{i} play so as to best fulfill his objective of minimizing/maximizing the payoff? Generally this depends on the opponents play - so it is not exactly a standard optimization problem. Instead (whenever it exists) the following concept for optimal play is used.
\subsection{Minimax equilibrium}
For the game $(\G,v)$, if there is an $\eta_v \in \Reals$ and strategies $\sigma^*,\tau^*$ for player 0 and 1 respectively so that
\begin{equation}
\begin{aligned}
    f^v(\sigma^*,\tau) \leq \eta_v \qquad & \text{ for all } \tau \in \ST{1} \\
    f^v(\sigma, \tau^*)  \geq \eta_v \qquad & \text{ for all } \sigma \in \ST{0}
\end{aligned} \label{eq:MinMax2}
\end{equation}
\newcommand{\eqminmax}{\eqref{eq:MinMax2}\ }
then the game $(\G,v)$ has a minimax equilibrium and $(\sigma^*,\tau^*)$ are called optimal strategies for \Player{0} and \Player{1} respectively. $\eta_v$ is called the value of the game.

The first inequality says that if \Player{0} follows $\sigma^*$, then payoff would always (against any play of \Player{1}) be below $\eta_v$, while the second inequality says that if \Player{1} follows $\tau^*$ then the payoff always be above $\eta_v$. In particular
\[
    f^v(\sigma^*,\tau^*) = \eta_v
\]
There may be many optimal strategy pairs $(\sigma^*,\tau^*)$ but value $\eta_v$ must be unique. This is because
\eqminmax are equivalent to
\begin{align}
    \eta_v = \min_{\sigma \in \ST{0}} \sup_{\tau \in \ST{1}} f^v(\sigma, \tau) = \max_{\tau \in \ST{1}} \inf_{\sigma \in \ST{0} } f^v(\sigma,\tau) \label{eq:MinMax}
\end{align}
(The distinction between $\max \text{ vs } \sup$ (or $\min \text{ vs } \inf$) is that the optimal value must be attained in the former, but may not be attained in the latter)

The RHS of \eqref{eq:MinMax} is the optimal payoff in the game where \Player{1} declares his strategy to \Player{0} before the game begins (which is always disadvantageous to \Player{1}). Similarly LHS of \eqref{eq:MinMax} is the optimal payoff when \Player{0} declares his strategy to \Player{1} in advance (which is always advantageous to \Player{1}). The equality means that both can reveal their optimal strategies $(\sigma^*,\tau^*)$ to the opponent and none will have an incentive to change their strategy.

Not every game has a minimax equilibrium, however a weaker version of \eqref{eq:MinMax} (also called as $\epsilon$-equilibrium) holds for a large class of payoffs (see  \cite{roux_equilibria})
\[
    \inf_{\sigma \in \ST{0}} \sup_{\tau \in \ST{1}} f^v(\sigma, \tau) = \sup_{\tau \in \ST{1}} \inf_{\sigma \in \ST{0} } f^v(\sigma,\tau)
\]

For the games to be discussed, \eqref{eq:MinMax} will explicitly be shown. The minimax will exist from each $v \in V$.  Since $(\sigma^*,\tau^*)$ are history dependent they can be chosen independent of $v$. Hence we can bundle up the values and associate to $\G$ a value vector $\eta \in \Reals^V$ given by $\eta = (\eta_v)_{v\in V}$. Let $f(\sigma,\tau) = (f^v(\sigma,\tau))_{v \in V}$, then we have (inequalities are coordinate-wise) --
\begin{equation}
    \begin{aligned}
    f(\sigma^*, \tau) \leq \eta \qquad \forall \tau \in \ST{1}\\
    f(\sigma,\tau^*) \geq \eta \qquad \forall \sigma \in \ST{0}
    \end{aligned}\label{eq:vecMinMax}
\end{equation}

\section{Finite Games}
\label{sec:finitegames}

We will now start with a simple yet important class of payoffs, and show the existence of minimax and optimal strategies for it.

A payoff function $f$ is finitely determined if there is a $N \in \Nat$ so that $f$ only depends on the outcomes in the first $N$ rounds. More precisely
\[
    \forall \alpha,\beta \in \PI\, \alpha|_N=\beta|_N \implies f(\alpha) = f(\beta)
\]
where $( v_0 v_1 \ldots )|_m = v_0v_1 \ldots v_m$.

If $f$ is finitely determined then call $\G=(G,f)$ a finite duration game. We can assume that the game stops after $N$ rounds have been played and the payoff is given by
\[
    f : \PF[N] \to \Reals
\]
This is defined as the payoff for an arbitrary infinite extension, which is well defined since $G$ has no dead ends and $f$ depends only on first $N$ rounds.

The following theorem is well known - it is sometimes called the backward induction technique. The backward induction, however, is not very explicit in the proof presented here.\\
\begin{theorem}
    \label{thm:finiteMinMax}
    Let $\G=(G,f)$ be a finite game. There is a $\eta \in \Reals^V$ and strategies $(\sigma^*, \tau^*)$ which satisfy \eqref{eq:vecMinMax}
\end{theorem}
\begin{proof}
    The proof is by induction on $N$ -- the duration of the game $\G$.
    \begin{description}
        \item[Base Case] $N=1$: Hence the game ends after the first move. Let
            \begin{align*}
                \eta_u &= \begin{dcases}
                    \min_{ v \in N(u) } f(uv) & \tif u \in V_0\\
                    \max_{ v \in N(u) } f(uv) & \tif u \in V_1
                    \end{dcases}
                    \intertext{And}
                    \sigma^*(u) &= \argmin_{ v \in N(u) } f(uv) \quad \tif u \in V_0 \\
                    \tau^*(u) &= \argmax_{ v \in N(u) } f(uv) \quad \tif u \in V_1
            \end{align*}
            Then \eqminmax follows for any $v$ by considering the cases $v \in V_0$ and $v \in V_1$ separately. Hence \eqref{eq:vecMinMax} follows with $\eta=(\eta_v)_{v\in V}$
        \item[Inductive Case] $N=k+1$ with $k \geq 1$: \\
            At the $\nth[k+1]$ round what will be the decision of the players? Suppose $v_0v_1\ldots v_k$ has been played. Now if $v_k \in V_1$, since this is the last round, \Player{1} will chose an $u$ which maximizes $f(v_0v_1\ldots v_ku)$. Similarly if $v_k \in V_0$, then \Player{0} will choose an $u$ which minimizes $f(v_0v_1\ldots v_ku)$.

        Motivated by this, define the $k$ step game $\G'=(G,f')$ where
            \[
                f'(v_0v_1 \ldots v_k) = \begin{dcases}
                    \min_{ u \in N(v_k) } f(v_0 v_1 \ldots v_k u) & \tif v_k \in V_0\\
                    \max_{ u \in N(v_k) } f(v_0 v_1 \ldots v_k u) & \tif v_k \in V_1
                \end{dcases}
            \]
            By induction hypothesis $\G'$ has a value vector $\eta$ and optimal strategies $(\sigma',\tau')$.
            Consider the aforementioned strategies for the $\nth[k+1]$ round -
            \begin{align*}
                \sigma_{k+1}(v_0 v_1 \ldots v_k) = \argmin_{ u \in N(v_k) } f(v_0 v_1 \ldots v_k u) \quad \tif v_k \in V_0 \\
                \tau_{k+1}(v_0 v_1 \ldots v_k) = \argmax_{ u \in N(v_k) } f(v_0 v_1 \ldots v_k u) \quad \tif v_k \in V_1
            \end{align*}
            Let $\sigma^*=[\sigma',\sigma_{k+1}]$ be the strategy for \Player{0} which plays $\sigma'$ for the first $k$ rounds, and $\sigma_{k+1}$ for the $\nth[k+1]$ round. Analogously define $\tau^*=[\tau',\tau_{k+1}]$ for \Player{1}.

            The following shows that $\eta$ is the value vector for \G\ and $(\sigma^*,\tau^*)$ are the optimal strategies.

            To prove the first inequality in \eqref{eq:vecMinMax}, take any path $v_0v_1 \ldots v_{k+1}$ that conforms with $\sigma^*$. Then $v_0v_1 \ldots v_k$ must conform with $\sigma'$. Hence
            \[
                f'(v_0 v_1 \ldots v_k) \leq \eta_{v_0}
            \]
            If $v_k \in V_0$ then $v_{k+1}=\sigma_{k+1}(v_0 v_1 \ldots v_k)$, hence
            \[
                f(v_0v_1 \ldots v_{k+1}) = f'(v_0v_1 \ldots v_k)
            \]
            Otherwise $v_k \in V_1$ and from the definition of $f'$
            \[
                f(v_0v_1 \ldots v_{k+1}) \leq f'(v_0v_1 \ldots v_k)
            \]
            In any case $f(v_0 v_1 \ldots v_{k+1}) \leq f'(v_0 v_1 \ldots v_k) \leq \eta_{v_0}$. This shows
            \[
                f(\sigma^*,\tau) \leq \eta \quad \forall \tau \in \ST{1}
            \]

            The proof of the second inequality follows verbatim by reversing the inequalities, replacing $\sigma$ by $\tau$ and interchanging $V_0$ and $V_1$. Hence this proves \eqref{eq:vecMinMax} for $\G$.
    \end{description}
\end{proof}
\section{Win Lose games}
\label{sec:winlose}
When $f$ is a $\set{0,1}$ valued function, the game has a win/loss interpretation. \Player{1} wins the play (and \Player{0} loses) whenever the payoff is $1$, otherwise \Player{1} loses the play (and \Player{0} wins). This game will be denoted by $\G=(G,Win)$ where
\[
Win = \set{ \alpha \mid f(\alpha) = 1} \subseteq \PI
\]
is the set for winning plays for \Player{1}.

\subsection{Determinacy}
A strategy $\sigma^*$ for \Player{0} is said to be a winning strategy from $v \in V$ if
\[
    \pi^v_{\sigma^*\tau} \not\in Win \quad \forall \tau \in \ST{1}
\]
Similarly a strategy $\tau^*$ for \Player{1} is a winning strategy from $v$ if
\[
    \pi^v_{\sigma\tau^*} \in Win \quad \forall \sigma \in \ST{0}
\]

\begin{definition}
\label{def:determinacy}
Call a win-lose game \emph{determined} if from every $v \in V$ either \Player{0} or \Player{1} has a winning strategy.
\end{definition}

Notice that both the players cannot simultaneously have a winning strategy starting from $v$. It is also possible that neither of them has one, but axiom of choice is required to show this. See \cite{martin_borel_1975} for a very general theorem on determinacy by Martin.

Suppose the game $\G=(G,f)$ (where $f$ is $\set{0,1}$ valued) has a minimax \eqminmax starting from $v$, then $\eta_v \in \set{0,1}$ (because of \eqref{eq:MinMax}). If $\eta=1$ then $\tau^*$ is a winning strategy for \Player{1}, otherwise $\eta=0$ and $\sigma^*$ is a winning strategy \Player{0}. Hence as a corollary of \autoref{thm:finiteMinMax} we have --
\\
\begin{corollary}
    \label{cor:finiteDeterminacy}
    If a winning condition $Win$ is finitely determined ($\exists N \, \forall \alpha,\beta \in \PI \, \alpha|_N = \beta|_N \implies \alpha \in Win \iff \beta \in Win$), then the game $\G=(G,Win)$ is determined.
\end{corollary}
