\chapter{Introduction}

\section{Formalism}
\label{sec:formalism}
Let's look at class of two player games. Denote the two players by 0 and 1.

Take a finite graph $G=(V,E)$ whose vertices are partitioned ($V = V_0 \sqcup V_1$) into those belonging to Player 0 and Player 1. Assume that $G$ has no dead ends ($\forall v \in V \exists w  (v,w) \in E$). Let $\PF$ denote the set of all finite paths in $G$, and by $\PI$ the set of all infinite paths in $G$.\\
The play starting at $v_0 \in V$ proceeds as follows -
\begin{itemize}
  \item A token is intitially placed in $v_0$
  \item At any stage if the token is in a vertex $v \in V_i$ ($i \in \set{0,1}$), then
        player i moves the token to a vertex $w$ so that $(v,w) \in E$
\end{itemize}
A concrete realization of this play will be an infinite path $\pi \in \PI$

\[
  \pi = v_0 v_1 v_2 \ldots
\]

Where -
\begin{itemize}
  \item $v_0$ was the veretx where the play started
  \item Assume $v_i \in V_j$, then at $i+1$th step, player $j$ decided to move the token to $v_{i+1} \in V$ such that $(v_i,v_{i+1}) \in E$.
\end{itemize}

After this infinite path $\pi$ is played, Player 0 is supposed to pay $f(\pi)$ units of money to Player 1, where $f$ is a function defined on infinite paths -

\[
    f : \PI \to \Reals
\]

Player 0's objective is to minimize the amount payed, while Player 1's objective is to maximize it.
This game will be denoted by $\G=(G,f,v_0)$.

\subsection{Strategy}
A strategy for player $i \in \set{0,1}$ is a function 
\begin{align}
    \sigma &: V^{*}V_i \cap \PF \mapsto V \\
    &\text{ s.t. } (u,\sigma(\alpha u)) \in E \quad \forall \alpha u \in \PF,\, u \in V_i \text{ and } \alpha \in V^*
\end{align}
Intuitively this is a recpie for player $i$ to make his moves in the game. If the path traced by the token is $\alpha u \in V^{*}V_i$ (hence it is currently in $V_i$), then the strategy recommends moving the token to the neighbor $\sigma(wu)$. This recepie prescribes what to do for any possible evolution of the game (and movement of the token).

When player 0 follows a strategy $\sigma$ and player 1 follows a strategy $\tau$ the game (starting at $v_0$) will evolve in an unique path 
\begin{align}
    \pi_{\sigma\tau} &= v_0v_1v_2\ldots\\
    \text{where}\nonumber\\
    v_{i+1} &= 
\begin{cases}
    \sigma(v_0v_1\ldots v_i) & \text{ if } v_i \in V_0\\
    \tau(v_0v_1\ldots v_i) & \text{ otherwise } (v_i \in V_1)
\end{cases}
\end{align}

Denote $f(\pi_{\sigma\tau})$ by $f(\sigma,\tau)$ and set of all strategies of player $i$ by \ST{i}.
\section{Optimal Play}
What is the optimal play for a player? The answer depends on how the other player plays, but if we assume that both players are rational and intelligent the the following gives a satisfactory answer - 

\subsection{Minmax equilibrium}
If there is an $\eta \in \Reals$ and strategies $\sigma^*,\tau^*$ for player 0 and 1 respectively so that
\begin{align}
    f(\sigma^*,\tau) \leq \eta \qquad & \text{ for all } \tau \in \ST{1}  \label{eq:MinMax0} \\
    f(\sigma, \tau^*)  \geq \eta \qquad & \text{ for all } \sigma \in \ST{0} \label{eq:MinMax1}
\end{align}
then the game $\mathcal{G}$ has is said to have minmax equilibrium, $\sigma^*$ and $\tau^*$ are called optimal strategies for player 0 and player 1 respectively, and $\eta$ is called the value of the game.

\eqref{eq:MinMax0} says that if player 0 follows strategy $\sigma^*$, then payoff would never be more than $\eta$, while \eqref{eq:MinMax1} says that if player 1 follows strategy $\tau^*$ then the payoff never be less than $\eta$. When they play $\sigma^*$ and $\tau^*$ simultaneously -- 
\[
    f(\sigma^*,\tau^*) = \eta
\]
follows by combining \eqref{eq:MinMax0} and \eqref{eq:MinMax1}.

\eqref{eq:MinMax0}, \eqref{eq:MinMax1} are equivalent to \eqref{eq:MinMax} below --
\begin{align}
    \eta = \min_{\sigma \in \ST{0}} \max_{\tau \in \ST{1}} f(\sigma, \tau) = \max_{\tau \in \ST{1}} \min_{\sigma \in \ST{0} } f(\sigma,\tau) \label{eq:MinMax}
\end{align}

The right hand side is the optimal payoff when Player 1 declares his strategy to Player 0 before the game begins (which is always disadvantageous to player 1). Similarly the left side is the optimal payoff when Player 0 declares his strategy to player 1 (which is always advantageous to player 1). The equality means that both of the players can declare their optimal strategy upfront and still not be at a disadvantage.

Not every game has a Minimax equilibrium, however a weaker version of \eqref{eq:MinMax} holds for a large class of games (see \cite{roux_equilibria}) --
\[
    \inf_{\sigma \in \ST{0}} \sup_{\tau \in \ST{1}} f(\sigma, \tau) = \sup_{\tau \in \ST{1}} \inf_{\sigma \in \ST{0} } f(\sigma,\tau)
\]

For the games to be discussed, \eqref{eq:MinMax} will explicitly be shown. Given that the minimax exist, it will be interesting to obtain algorithms to find an optimal pair of strategies $(\sigma^*,\tau^*)$ when \G\ is finitely presented.

\begin{theorem}[Finite game]
    \label{thm:finiteMinMax}
    Let $G=(V_0 \sqcup V_1,E)$ be a finte graph without dead ends, let $v_0 \in V(=V_0 \sqcup V_1)$, and suppose there is a $N \in \mathbb{N}$ so that the payoff $f$ only depends on first $N$ vertices of a path. (i.e. $f(\alpha) = f(\beta)$ for every $\alpha,\beta \in \PI$ such that $\alpha|_N = \beta|_N$). The game $\G=(G,f,v_0)$ has a Minimax equilibrium.
\end{theorem}
\begin{proof}
    Let $\PF[m]$ denote the set of paths in $G$ of length $m$. Since $f$ only depends on first $N$ vertices we can assume
    \[
        f : \PF[N] \mapsto \Reals
    \]
    and that the games stops after $N$ rounds (because playing further is not going to change the payoff).

    At the $(N-1)$th round, what will be the decision of the players? Supposed $v_0v_1\ldots v_{N-1}$ has been played. Now if $v_{N-1} \in V_1$, the player 1 will chose a neighbor $u$ which maximizes $f(v_0v_1\ldots v_{N-1}u)$ as the game is going to end in the next round. Similarly if $v_{N-1} \in V_0$, then player 0 will choose a $u$ which minimizes $f(v_0v_1\ldots v_{N-1}u)$. This motivates the following definition.

Define 
\[
    f^m : \PF[m] \mapsto \Reals \qquad m=0,1\ldots N
\]
by $f^N \defeq f$ and recursively for $m=N-1$ to $0$
\begin{align}
    f^m (u_0u_1\ldots u_m) &= 
    \begin{cases}
        \min_{(u_m,v) \in E} f^{m+1}(u_0u_1\ldots u_m v) & \text{ if } u_m \in V_0\\
        \max_{(u_m,v) \in E} f^{m+1}(u_0u_1\ldots u_m v) & \text{ if } u_m \in V_1\\
    \end{cases} \label{eq:ValMinMax}
\end{align}

This also gives a strategy for the players. For player 0 -
\begin{align}
    \sigma^* : \PF[<N] \cap V^{*}V_0 &\mapsto V\\
    \sigma^*(u_0u_1\ldots u_k) &= \argmin_{v} f^{k+1}(u_0u_1\ldots u_k v)
\end{align}

Similarly for player 1 -
\begin{align}
    \tau^* : \PF[<N] \cap V^{*}V_1 &\mapsto V\\
    \tau^*(u_0u_1\ldots u_k) &= \argmax_{v} f^{k+1}(u_0u_1\ldots u_k v)
\end{align}
These strategies suggest playing the neighbors which obtain the optimum in \eqref{eq:ValMinMax}

The following shows that $(\sigma^*,\tau^*)$ satisfy \eqref{eq:MinMax0},\eqref{eq:MinMax1} with $\eta = f^0(v_0)$.

\begin{claim}
    Starting at an existing $u_0u_1\ldots u_k \in \PF[k]$ (with $k \leq N$), using $\sigma^*$ player 0 can always (against any play of player 1) ensure payoff $\leq \eta$, and using $\tau^*$ player 1 can always ensure payoff $\geq \eta$, where $\eta = f^k(u_0u_1\ldots u_k)$.
\end{claim}
\begin{claimproof}
    The proof is by induction on $N-k$
    \begin{description}
        \item[$N-k=0$] Hence $k=N$, no moves will be played anymore, and the payoff is exactly $\eta$ -- which satisfies the required conditions. 
        \item[$N - k = (i+1)$] and assume induction hypothesis for $N-k=i$.\\
            We prove the first part (i.e using $\sigma^*$ Player 0 can always ensure $\leq \eta$), the corresponding argument for player 1 is similar.
            \begin{itemize}
                \item[Case 1] $u_k \in V_0$ It's Player 0's turn, and the token will be moved to $ u_{k+1} = \sigma^*(u_0u_1\ldots u_k)$ which satisfies -

                    \[
                        \eta = f^{k+1}(u_0 u_1 \ldots u_k u_{k+1})
                    \]
                    Since by induction hypothesis, starting at $u_0 u_1 \ldots u_{k+1}$ and playing $\sigma^*$ player 0 will get at least $\eta$, it also happens srating at $u_0 u_1 \ldots u_{k}$.
                \item[Case 2] $u_k \in V_1$ Suppose Player 1 moves the token to some $u_{k+1}$, then from \eqref{eq:ValMinMax}
                    \[
                        \eta = f^k(u_0 u_1 \ldots u_k) \geq f^{k+1}(u_0 u_1 \ldots u_k u_{k+1}) = \eta'
                    \]
                    By induction hypothesis from $u_0 u_1 \ldots u_{k+1}$ Playing $\sigma^*$ will keep the payoff $\leq \eta'$ and hence $\leq \eta$.
            \end{itemize}
    \end{description}
\end{claimproof}

Hence, for the game starting at $v_0$, $(\sigma^*, \tau^*)$ are the optimial strategies with the value $\eta = f^0(v_0)$. Notice that the recursive equations \eqref{eq:ValMinMax} also provide an algorithm to compute $\sigma^*, \tau^*$ and $\eta$. This is also called the minimax algortihm.
\end{proof}

\section{Win Lose games}
\label{sec:winlose}
Now assume $f$ is a $\set{0,1}$ valued function. Then whenever the payoff is $1$ say that player 1 wins, and when the payoff is $0$ say that player 0 wins. This can also be dentoted by $Win = \set{ \alpha \mid f(\alpha) = 1} \subseteq \PI$ -- the winning set for player 1. If such a game has a minimax \eqref{eq:MinMax}, then $\eta \in \set{0,1}$. If $\eta=1$, then $\tau^*$ is a winning strategy for player 1, and if $\eta=0$, then $\sigma^*$ is a winning strategy for player 0.

In Win Lose game the property corresponing to \eqref{eq:MinMax} is called determinacy. A game $\G=(G,Win)$ is said to be determined if either player 0 or player 1 has a winning strategy. A winning strategy is a strategy that wins the game against any possible move of the opponent. Note that both the players cannot simultaneously have winning strategies (because then who wins when they play their respective winning strategies?), but it is possible that both of them don't have it either (however, Axiom of choice is required to show this).

\begin{corollary}[Theorem \ref{thm:finiteMinMax}]
    \label{cor:finiteDeterminacy}
    If a winning condition $Win$ is finitely determined ($\exists N \, \forall \alpha,\beta \in \PI \, \alpha|_N = \beta|_N \implies \alpha \in Win \iff \beta \in Win$), then the game is determined.
\end{corollary}

\begin{example}
    In Chess, either White has a winning strategy, or black has a strategy to either or draw.
    %TODO: Such games are better modelled using {-1,0,1} valued payoff.
\end{example}
